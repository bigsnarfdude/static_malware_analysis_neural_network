#!/usr/bin/env python


"""
training basic Keras/Tensorflow based MLP with histogram data
for malware classification based on 10 classes
dumps json for model
dumps trained weights folder
"""


from __future__ import print_function

import pandas as pd
import numpy as np
import cPickle as pickle
import hickle
import set_up
import scipy.sparse as sp
from sklearn.externals import joblib
import os
import random

import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop

import logging
reload(logging)
logging.basicConfig(format = u'[%(asctime)s]  %(message)s', level = logging.INFO)
logging.info('[Script for training basic MLP with histogram data]')

# assembling train
logging.info('[train] Load data...')
trainLabels = pd.read_csv('/datadisk/kaggle-malware/data/raw/trainLabels.csv')

num_classes=10

model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(21706,)))
model.add(Dropout(0.2))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(num_classes, activation='softmax'))
model.summary()
model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])


def manual_batch_run(trainLabels):
    num_classes = 10
    data = []
    indices = []
    ptrs = [0]
    cur_bound = 0
    train_labels = []
    n = 200
    rand_targets = random.sample(list(trainLabels.iterrows()), n)

    for i, row in rand_targets:
        train_labels.append(row['Class'])
        fname = set_up.feats_folder_path + '4gr/' + '{}.bytes.freq'.format(row['Id'])
        (inds, vals) = pickle.load(open(fname, 'r'))
        assert len(vals) == len(inds)
        #Out[17]: 677696
        data.extend(vals)
        indices.extend(inds)
        cur_bound += len(vals)
        ptrs.append(cur_bound)

    X = sp.csr_matrix((np.array(data), np.array(indices), np.array(ptrs)), dtype=int)
    del cur_bound, data, indices, ptrs
    x_train = X.toarray()
    del X
    y_train = keras.utils.to_categorical(train_labels, num_classes)
    return (x_train, y_train)
   

for full_batch in range(500):
    logging.info('[Full Batch Manual Run]')
    x_train, y_train = manual_batch_run(trainLabels)
    model.fit(x_train, y_train,
          epochs=1,
          batch_size=50)

# serialize model to JSON
model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights("model.h5")
print("Saved model to disk")

print("Done training nn")
