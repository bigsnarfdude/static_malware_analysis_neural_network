from __future__ import print_function

import pandas as pd
import numpy as np
import cPickle as pickle
import hickle
import config as CFG
import scipy.sparse as sp
from sklearn.externals import joblib
import os
import random

import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop

from keras.models import model_from_json

import logging
reload(logging)
logging.basicConfig(format = u'[%(asctime)s]  %(message)s', level = logging.INFO)
logging.info('[Script for 1st stage feature selection by SVC]')

# assembling train
logging.info('[test] Loading data ...')
testLabels = pd.read_csv(CFG.testing_data_directory_path)
logging.info('[evalutation] Loading data ...')
evaluationLabels = pd.read_csv(CFG.training_data_directory_path)

num_classes=10

def manual_batch_run(evaluationLabels):
    num_classes = 10
    data = []
    indices = []
    ptrs = [0]
    cur_bound = 0
    evaluation_labels = []
    n = 10
    rand_targets = random.sample(list(evaluationLabels.iterrows()), n)

    for i, row in rand_targets:
        evaluation_labels.append(row['Class'])
        fname = CFG.feats_folder_path + '4gr/' + '{}.bytes.freq'.format(row['Id'])
        (inds, vals) = pickle.load(open(fname, 'r'))
        print(fname)
        assert len(vals) == len(inds)
        #Out[17]: 677696
        data.extend(vals)
        indices.extend(inds)
        cur_bound += len(vals)
        ptrs.append(cur_bound)

    X = sp.csr_matrix((np.array(data), np.array(indices), np.array(ptrs)), dtype=int)
    del cur_bound, data, indices, ptrs
    x_train = X.toarray()
    del X
    y_train = keras.utils.to_categorical(evaluation_labels, num_classes)
    return (x_train, y_train)


for evaluation in range(1):
    logging.info('[Evaluation Run]')
    X, Y = manual_batch_run(evaluationLabels)

    # load json and create model
    json_file = open('model_200.json', 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    loaded_model = model_from_json(loaded_model_json)
    # load weights into new model
    loaded_model.load_weights('model_200.h5')
    print('Loaded model from disk')

    # evaluate loaded model on test data
    loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
    score = loaded_model.evaluate(X, Y, verbose=0)
    print('*******************************************************')
    print('%s: %.2f%%' % (loaded_model.metrics_names[1], score[1]*100))
    score = loaded_model.evaluate(X, Y, verbose=0)

print('Done')
