"""
eval_nn.py
"""

from __future__ import print_function

import pandas as pd
import numpy as np
import config as CFG
import os
import random
import cPickle as picke
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop

from keras.models import model_from_json

import logging
reload(logging)
logging.basicConfig(format = u'[%(asctime)s]  %(message)s', level = logging.INFO)
logging.info('[DeSer model and test against random sample of train]')

# assembling train
logging.info('[test] Loading data ...')
testLabels = pd.read_csv(CFG.testing_data_directory_path)
logging.info('[evaluation] Loading data ...')
evaluationLabels = pd.read_csv(CFG.training_data_directory_path)

num_classes=10

def evaluation_batch_run(evaluationLabels):
    num_classes = 10
    data = []
    indices = []
    ptrs = [0]
    cur_bound = 0
    evaluation_labels = []
    n = 100 # evaluate 100 train samples
    rand_targets = random.sample(list(evaluationLabels.iterrows()), n)

    for i, row in rand_targets:
        evaluation_labels.append(row['Class'])
        fname = CFG.feats_folder_path + '4gr/' + '{}.bytes.freq'.format(row['Id'])
        (inds, vals) = pickle.load(open(fname, 'r'))
        print(fname)
        assert len(vals) == len(inds)
        data.extend(vals)
        indices.extend(inds)
        cur_bound += len(vals)
        ptrs.append(cur_bound)

    X = sp.csr_matrix((np.array(data), np.array(indices), np.array(ptrs)), dtype=int)
    del cur_bound, data, indices, ptrs
    x_train = X.toarray()
    del X
    y_train = keras.utils.to_categorical(evaluation_labels, num_classes)
    return (x_train, y_train)


for evaluation in range(1):
    logging.info('[Evaluation Run]')
    X, Y = evaluation_batch_run(evaluationLabels)

    # load json and create model
    json_file = open('model.json', 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    loaded_model = model_from_json(loaded_model_json)
    # load weights into new model
    loaded_model.load_weights('model.h5')
    logging.info('[Loaded model from disk']

    # evaluate loaded model on test data
    loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
    score = loaded_model.evaluate(X, Y, verbose=0)
    print('*******************************************************')
    print('%s: %.2f%%' % (loaded_model.metrics_names[1], score[1]*100))
    score = loaded_model.evaluate(X, Y, verbose=0)

logging.info('[Done Neural Network Evaluation]')

